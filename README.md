# ASL chatbot
This project involves the development of an AI chatbot that combines Natural Language 
Processing (NLP) and Computer Vision techniques to facilitate inclusive communication. The 
chatbot will seamlessly interpret both text-based and sign language inputs, utilizing advanced 
NLP algorithms for understanding textual information and computer vision models for 
recognizing and translating sign language gestures into text. Application programming 
interface (API) integration with platforms like OpenAI will enhance language processing 
capabilities, while leveraging popular computer vision libraries such as OpenCV will enable 
precise gesture recognition. The project aims to create an accessible and user-friendly interface 
utilizing image recognition of sign language hand gestures integrated with a chatbot to provide 
text-based output, fostering inclusive interaction between individuals using sign language and 
AI systems
